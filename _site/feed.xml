<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-03-31T13:42:45-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Keltin Grimes</title><subtitle>This is the portfolio of Keltin Grimes. He is an AI/ML researcher at  Carnegie Mellon&apos;s Software Engineering Institute and broadly interested in AI Safety.</subtitle><entry><title type="html">Molecular Prediction</title><link href="http://localhost:4000/2023/06/06/molecular-prediction.html" rel="alternate" type="text/html" title="Molecular Prediction" /><published>2023-06-06T16:56:18-04:00</published><updated>2023-06-06T16:56:18-04:00</updated><id>http://localhost:4000/2023/06/06/molecular-prediction</id><content type="html" xml:base="http://localhost:4000/2023/06/06/molecular-prediction.html"><![CDATA[<p>At the start of 2021 I joined professor Noa Marom’s group in Carnegie Mellon’s Depeartment of Materials Science and Engineering. Her team was beginning a project to predict the band gap of molecules and crystals, the critical property in developing solar cells, and I was excited to apply my machine learning knowledge to a new domain.</p>

<p>I have led the project’s exploration of deep learning models. We began our work by applying two state-of-the-art deep learning models designed for general molecular property prediction to a new dataset with a much more diverse set of molecules (more atoms, new elements, different structures, etc.). I set up a hyperparameter tuning system using bayesian optimization and wrote scripts to train the models (one PyTorch, one TensorFlow) on a large U.S. government GPU server. These experiments gave us strong baselines with which to buid off of.</p>

<p>Since the way these molecules are collected is a very time-intensive process, our main goal was to achieve a high predictive performance with as little data as possible. To this end we modified our best performing model so that we could perform active learning and ideally improve the data efficiency. We did this by replacing the model’s final dense layer with a bayesian layer, where each weight has a distribution with some mean and variance. This gives us stochastic predictions, allowing us to estimate uncertainty and add the molecules with the greatest uncertainty to our training pool.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[At the start of 2021 I joined professor Noa Marom’s group in Carnegie Mellon’s Depeartment of Materials Science and Engineering. Her team was beginning a project to predict the band gap of molecules and crystals, the critical property in developing solar cells, and I was excited to apply my machine learning knowledge to a new domain.]]></summary></entry><entry><title type="html">Data Report Portfolio</title><link href="http://localhost:4000/2023/04/14/data-reports.html" rel="alternate" type="text/html" title="Data Report Portfolio" /><published>2023-04-14T16:56:18-04:00</published><updated>2023-04-14T16:56:18-04:00</updated><id>http://localhost:4000/2023/04/14/data-reports</id><content type="html" xml:base="http://localhost:4000/2023/04/14/data-reports.html"><![CDATA[<p>This page contains a selection of data analysis reports that I have written for a variety of classes during my time at CMU.</p>

<p>Below is a document analyzing changes in the usage of Boston’s bike-sharing network before and after the COVID-19 outbreak. This was a group
project for my Statistical Visualization course where we showed off a variety of plots for a variety of different data types.</p>

<p><a href="/assets/post_assets/2023-04-14-data-reports//Bike-Sharing-Report.html">(<i>open in new tab</i>)</a></p>

<embed type="text/html" src="/assets/post_assets/2023-04-14-data-reports//Bike-Sharing-Report.html" width="100%" height="400px" style="border: 1px solid black" />

<p>The rest of the documents are reports from a two-course series on the statistical theory of linear regression and other fundamental
statistics concepts.</p>

<ul>
    <li>
        <a href="/assets/post_assets/2023-04-14-data-reports//report-GMP.pdf">(link)</a>
        <b>An analysis of per-capita GMP for a (fake) corporate client.</b>
        <i>Focus on: Linear Regression, Bootstrap, Kernel Regression.</i>
    </li>
    <li>
        <a href="/assets/post_assets/2023-04-14-data-reports//report-loans.pdf">(link)</a>
        <b>A (mock) report for the US Small Business Administration on the relationship between loans given and jobs created.</b>
        <i>Focus on: Poisson Regression, Generalized Linear/Additive Models.</i>
    </li>
    <li>
        <a href="/assets/post_assets/2023-04-14-data-reports//report-plant-species.pdf">(link)</a>
        <b>Analysis of plant species on various islands.</b>
        <i>Focus on: Linear Regression.</i>
    </li>
    <li>
        <a href="/assets/post_assets/2023-04-14-data-reports//report-abalones.pdf">(link)</a>
        <b>Modeling the age of abalones.</b>
        <i>Focus on: Linear Regression, Additive Models, Random Forests.</i>
    </li>
    <li>
        <a href="/assets/post_assets/2023-04-14-data-reports//report-patient-satisfaction.pdf">(link)</a>
        <b>Analysis of patient satisfaction.</b>
        <i>Focus on: Logistic Regression, Causal Effect Analysis, other classification models.</i>
    </li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[This page contains a selection of data analysis reports that I have written for a variety of classes during my time at CMU.]]></summary></entry><entry><title type="html">ASR Quick Adaptation Tool</title><link href="http://localhost:4000/2021/03/07/qat.html" rel="alternate" type="text/html" title="ASR Quick Adaptation Tool" /><published>2021-03-07T15:56:18-05:00</published><updated>2021-03-07T15:56:18-05:00</updated><id>http://localhost:4000/2021/03/07/qat</id><content type="html" xml:base="http://localhost:4000/2021/03/07/qat.html"><![CDATA[<p>For the summer of 2021, I was a Software Development Engineer at Amazon, working in the Alexa Shopping Automatic Speech Recognition (ASR) division. The data scientists I worked with regularly have to go through a long process of adapting the production Alexa ASR model to new or underperforming use-cases. A customer would come to us with some word or phrase that ASR model was not recognizing often enough, and the data scientists had to fine-tune the model to ensure the word or phrase was properly recognized. This process took a long time, mostly because of the need to obtain human voices from a data provider.</p>

<p>The ASR Quick Adaptation Tool, which I developed during my time at Amazon, automated the inital steps of this process, including the baseline model evaluation to assess current performance. Most importantly, it enabled the user to use synthetically generated audio. This meant the necessary audio could be acquired in a matter of hours, rather than weeks. Our experiments showed that the synthetically generated audio was of sufficient quality to replace the human audio, so this elimated the largest bottleneck in the adaptation process.</p>

<p>I created the tool as a command line interface using Python. The development process involved connecting multiple APIs together and interfacing with cloud storage, all within a secure computing environment.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[For the summer of 2021, I was a Software Development Engineer at Amazon, working in the Alexa Shopping Automatic Speech Recognition (ASR) division. The data scientists I worked with regularly have to go through a long process of adapting the production Alexa ASR model to new or underperforming use-cases. A customer would come to us with some word or phrase that ASR model was not recognizing often enough, and the data scientists had to fine-tune the model to ensure the word or phrase was properly recognized. This process took a long time, mostly because of the need to obtain human voices from a data provider.]]></summary></entry><entry><title type="html">Ode to Transformer</title><link href="http://localhost:4000/2021/03/07/ode-to-transformer.html" rel="alternate" type="text/html" title="Ode to Transformer" /><published>2021-03-07T15:56:18-05:00</published><updated>2021-03-07T15:56:18-05:00</updated><id>http://localhost:4000/2021/03/07/ode-to-transformer</id><content type="html" xml:base="http://localhost:4000/2021/03/07/ode-to-transformer.html"><![CDATA[<p>The transformer-based neural networks have become the state of the art in Natural Language Processing, most notably in
text generation. They can create paragraphs that would easily fool you into thinking they were written by humans. But how well
could they grasp the concept of poetry?</p>

<p>To find out, I took one of the leading text-generation models at the time, called GPT-2, created by OpenAI, and fine-tuned it on
a large collection of English-language poetry. It did not take much fiddling to produce some really interesting results. I trained
the model in such a way that all you had to do was provide the model with a title, and it would generate the body of the poem. Here
are some of the results.</p>

<div class="poem_title" style="margin-left: 40px">
    A Rainy Afternoon
</div>
<div class="poem_body" style="margin-left: 40px">
    I have a dream, a vision of the past; <br />
    A cloudless sky and an ocean's calm, <br />
    I am alone in my room with the stars, <br />
    And they are all asleep on their way to heaven. <br />
    The moon is shining through the window pane; <br />
    She has gone down into her silver bed: <br />
    Her face looks like a mirror that was made for me!
</div>

<div class="poem_title" style="margin-left: 40px">
    Dusk
</div>
<div class="poem_body" style="margin-left: 40px">
    She sits alone, so full and calm, <br />
    Yet looks to every hour of night, <br />
    And turns her lips in silent vow, <br />
    She dreams on a far-off sea <br />
    That is deep and sad and still.
</div>

<p>I hosted my trained model on the Google Cloud AI Training and Prediction Service, and created a web interface with ReactJS to request
poems from the model.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[The transformer-based neural networks have become the state of the art in Natural Language Processing, most notably in text generation. They can create paragraphs that would easily fool you into thinking they were written by humans. But how well could they grasp the concept of poetry?]]></summary></entry><entry><title type="html">Terrace</title><link href="http://localhost:4000/2019/12/21/terrace.html" rel="alternate" type="text/html" title="Terrace" /><published>2019-12-21T15:56:18-05:00</published><updated>2019-12-21T15:56:18-05:00</updated><id>http://localhost:4000/2019/12/21/terrace</id><content type="html" xml:base="http://localhost:4000/2019/12/21/terrace.html"><![CDATA[<p>In the summer of 2020, I interned at the Laboratory for Analytic Sciences (LAS). LAS is a research organization, run as a partnership
between North Carolina State University and the National Security Agency.</p>

<p>I ran my own project which focued on figuring out how to improve the process of extracting important information from large collections
of documents. I frst performed a series of experiments involving training various machine learning models on datasets of categorized
documents, to see if it was possible to predict which documents a person would find important. I found that it could be done with high
accuracy using large neural networks, but the model training was too slow for any interactive system.</p>

<p>I approached the problem as a classification task. A user presented with a huge dump of documents will want to separate them into two categories:
important or unimportant. As the user works through the documents, they will be able to easily label them, and a ML model can be used to learn the
distinction.</p>

<p>My final solution made use of two important techniques. First, it used a XGBoost model to do real-time active learning<sup>1</sup> with the user. The
model can be trained quickly to achieve reasonable performance, so the documents presented to the user to label can be updated often. This is important
for maximizing the knowledge gained by each document. Second, a large neural network was trained in the background to provide the most accurate predictions.
Since the training process for this model was slow, it was not suitable for real-time feedback, but it was important to update the application with high-accuracy
predictions every so often.</p>

<p><img src="/assets/post_assets/2020-09-05-terrace/las.png" style="width:75%; margin: 5px auto; display: block;" /></p>

<p>For any AI-powered service with non-technical users, it is important for the process to be interpretable as possible. To promote interpretablity, I did two
key things. First, I embedded each document as a 2D vector, and plotted them as shown above. I then color-coded the points as to whether the models thought
the document was important or not. This allows the user to visually interpret the model’s predictions. Second, I extracted the words the models most closely
associated with important documents. This can demonstrate why the models think certain documents are important.</p>

<p><sup>1</sup>Active learning is a process where the model being trained suggests data-points for the human to label. By labeling points where the model is unsure,
it has been shown that models can achieve the same accuracy for much less data.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[In the summer of 2020, I interned at the Laboratory for Analytic Sciences (LAS). LAS is a research organization, run as a partnership between North Carolina State University and the National Security Agency.]]></summary></entry><entry><title type="html">Salvation</title><link href="http://localhost:4000/2019/12/21/salvation.html" rel="alternate" type="text/html" title="Salvation" /><published>2019-12-21T15:56:18-05:00</published><updated>2019-12-21T15:56:18-05:00</updated><id>http://localhost:4000/2019/12/21/salvation</id><content type="html" xml:base="http://localhost:4000/2019/12/21/salvation.html"><![CDATA[<p>15-112, or Fundamentals of Programming and Computer Science, is Carnegie Mellon University’s main introductory computer science
course. For the final three weeks of class, the students are tasked with creating a term project that is complex and interactive,
the rest is up to them. My project was named Salvation:</p>

<p><img src="/assets/post_assets/2019-12-20-salvation/tp3_home.png" style="width:75%; margin: 5px auto; display: block;" /></p>

<p>Salvation is a pseudo-3D first person shooter where you must battle through monster-filled levels to escape, picking up valuable
items along the way. There are three modes: Campaign, with three pre-made levels; Random, where a map is randomly generated;
and the Level Editor, where players can construct their own maps. The method used to create the 3D view is called raycasting,
which I learned about from <a href="https://lodev.org/cgtutor/raycasting.html" target="_blank">here</a>.</p>

<p><img src="/assets/post_assets/2019-12-20-salvation/tp3_gameplay.png" style="width:75%; margin: 5px auto; display: block;" /></p>

<p>Out of more than 450 students, I was one of 12 selected to present my project in front of the rest of the class. A short video
I made about my project can be found <a href="https://youtu.be/T4oPAS3Nhwo" target="_blank">here</a> and a gallery of the
whole class’s projects is <a href="http://www.kosbie.net/cmu/fall-19/15-112/gallery.html" target="_blank">here</a>.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[15-112, or Fundamentals of Programming and Computer Science, is Carnegie Mellon University’s main introductory computer science course. For the final three weeks of class, the students are tasked with creating a term project that is complex and interactive, the rest is up to them. My project was named Salvation:]]></summary></entry><entry><title type="html">Kinship Classifier</title><link href="http://localhost:4000/2019/08/12/kinship-classifier.html" rel="alternate" type="text/html" title="Kinship Classifier" /><published>2019-08-12T16:56:18-04:00</published><updated>2019-08-12T16:56:18-04:00</updated><id>http://localhost:4000/2019/08/12/kinship-classifier</id><content type="html" xml:base="http://localhost:4000/2019/08/12/kinship-classifier.html"><![CDATA[<p>As I mentioned on the home page of this website, I am a Kaggler. Kaggle is a website that hosts data science competitions,
with a wide variety of topics and prizes, and I enjoy trying my hand at some of the contests. For the Recognizing Faces in
the Wild competition, the topic of this page, the task was to determine whether two faces share a parent-child relationship
from only two images.</p>

<p>Early on in the competition, it became obvious that there was one method that was going to produce the best results. I chose
to take a different approach, one that would not perform as well in the competition but was something I would find more interesting.
I used a facial landmark predictor from DLib (demonstrated on a sibling relationship below) and two pretrained models, Facenet and VGGFace, to generate a
vast array of features, and then determined which were the most effective by using Lasso logistic regression. The technique ended
up with a best competition score of 0.709, but I placed 54th out of 563 with a score of 0.905 by using a weighted average of a number
of other techniques.</p>

<div><img src="/assets/post_assets/2019-08-12-kinship-classifier/face_detection.jpg" style="width:75%; margin: 5px auto; display: block;" /></div>

<p>The ‘kernel’ I created detailing my work, as well as much more information about the competition, can be found on Kaggle’s website
<a href="https://www.kaggle.com/keltingrimes/feature-generation-and-analysis" target="_blank">here</a>.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[As I mentioned on the home page of this website, I am a Kaggler. Kaggle is a website that hosts data science competitions, with a wide variety of topics and prizes, and I enjoy trying my hand at some of the contests. For the Recognizing Faces in the Wild competition, the topic of this page, the task was to determine whether two faces share a parent-child relationship from only two images.]]></summary></entry><entry><title type="html">Asset Manager</title><link href="http://localhost:4000/2018/09/02/asset-manager.html" rel="alternate" type="text/html" title="Asset Manager" /><published>2018-09-02T16:56:18-04:00</published><updated>2018-09-02T16:56:18-04:00</updated><id>http://localhost:4000/2018/09/02/asset-manager</id><content type="html" xml:base="http://localhost:4000/2018/09/02/asset-manager.html"><![CDATA[<p>One day in April, 2018, I was asked to help move some equipment for the IT Department of the North Carolina State University
Department of Materials Science and Engineering. I was so good at carrying computers and unscrewing hard-drives that I
was asked to work on a large software project.</p>

<p>I ended up creating a database and corresponding interface to manage the computers, printers, monitors, etc. (called assets) of the
department. The SQL database holds a complex web of tables and the interface, made with HTML, CSS, PHP, SQL, and javascript,
allows for asset data to easily be added, accessed, deleted, and updated. Developed from April to September, 2018, the system
now manages thousands of assets and continues to save the MSE Department time and resources.</p>

<p><img src="/assets/post_assets/2018-09-02-asset-manager/am_ss.png" style="width:75%; margin: 5px auto; display: block;" /></p>

<p>This screenshot is from the end of the development phase, before the code was migrated to NC State’s secure servers.
George Martell, the IT Manager, taught me SQL and PHP and otherwise helped me throughout the project.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[One day in April, 2018, I was asked to help move some equipment for the IT Department of the North Carolina State University Department of Materials Science and Engineering. I was so good at carrying computers and unscrewing hard-drives that I was asked to work on a large software project.]]></summary></entry><entry><title type="html">Photoconversion</title><link href="http://localhost:4000/2018/07/30/photoconversion.html" rel="alternate" type="text/html" title="Photoconversion" /><published>2018-07-30T17:56:18-04:00</published><updated>2018-07-30T17:56:18-04:00</updated><id>http://localhost:4000/2018/07/30/photoconversion</id><content type="html" xml:base="http://localhost:4000/2018/07/30/photoconversion.html"><![CDATA[<p>From June 26 to July 27, 2018, I interned at the South Korean university Daegu-Gyeongbuk Institute of Science and Technology Department of Energy Science and Engineering under Professor Su-Il In. I assisted graduate students Saurav Sorcar and Ali Shahzad in their effort to develop a material that uses sunlight to convert carbon dioxide into hydrocarbon fuel at industrial efficiencies.</p>

<p>In a break from my previous experience, I worked in the lab every day, setting up photocatalytic experiments and sythesizing samples. I was able to put my data science skills to use, however, as I wrote an R script to calculate and plot incremental efficiencies and derivitaves of the sample output, data that was an integral part of the paper that I co-authored on the subject.</p>

<p><img src="/assets/post_assets/2018-07-30-photoconversion/catalyst_efficiencies.jpeg" style="width:75%;" /></p>

<p>The paper below discusses the results of our reduced blue-titania photocatalyst, sensitized with bimetallic Cu–Pt nanoparticles, and its world-class sustained and peak efficiencies.</p>

<ul>
    <li>Sorcar, Saurav, et al. <a href="https://pubs.rsc.org/en/content/articlelanding/2019/ee/c9ee00734b#!divAbstract" target="_blank">
        “CO2, Water, and Sunlight to Hydrocarbon Fuels: a Sustained Sunlight to Fuel (Joule-to-Joule) Photoconversion
        Efficiency of 1%.”</a> <i>Energy &amp; Environmental Science</i>, 21 May 2019, doi:10.1039/c9ee00734b.</li>
</ul>]]></content><author><name></name></author><summary type="html"><![CDATA[From June 26 to July 27, 2018, I interned at the South Korean university Daegu-Gyeongbuk Institute of Science and Technology Department of Energy Science and Engineering under Professor Su-Il In. I assisted graduate students Saurav Sorcar and Ali Shahzad in their effort to develop a material that uses sunlight to convert carbon dioxide into hydrocarbon fuel at industrial efficiencies.]]></summary></entry><entry><title type="html">Madden Playcalling</title><link href="http://localhost:4000/2018/02/21/madden-playcalling.html" rel="alternate" type="text/html" title="Madden Playcalling" /><published>2018-02-21T15:56:18-05:00</published><updated>2018-02-21T15:56:18-05:00</updated><id>http://localhost:4000/2018/02/21/madden-playcalling</id><content type="html" xml:base="http://localhost:4000/2018/02/21/madden-playcalling.html"><![CDATA[<p>The second phase of my time at the NC State University Department of Statistics took place in Professor Eric Laber’s Laber Labs. I joined graduate students
Nick Kapur and James Gilman on their project to improve playcalling in the NFL. To overcome the issues with limited games and the
exploration-stifling risk in the actual NFL, we simulated football games in the popular video-game Madden NFL, allowing us to
have vastly more data and the freedom to explore playcalling techniques. Raspberry Pi’s were connected to X-Box controllers to
manuever through the game menu and the data were scraped from screenshots of the game. When I left the project we had 5 systems
running 24 hours a day with more planned.</p>

<p>I worked on the project from December, 2017 to April, 2018, creating data visualizations and writing Python scripts for various aspects
of the complex system.</p>

<p><img src="/assets/post_assets/2018-02-21-madden-playcalling/madden_screen.png" alt="Madden Screenshot" style="width:75% " /></p>]]></content><author><name></name></author><summary type="html"><![CDATA[The second phase of my time at the NC State University Department of Statistics took place in Professor Eric Laber’s Laber Labs. I joined graduate students Nick Kapur and James Gilman on their project to improve playcalling in the NFL. To overcome the issues with limited games and the exploration-stifling risk in the actual NFL, we simulated football games in the popular video-game Madden NFL, allowing us to have vastly more data and the freedom to explore playcalling techniques. Raspberry Pi’s were connected to X-Box controllers to manuever through the game menu and the data were scraped from screenshots of the game. When I left the project we had 5 systems running 24 hours a day with more planned.]]></summary></entry></feed>